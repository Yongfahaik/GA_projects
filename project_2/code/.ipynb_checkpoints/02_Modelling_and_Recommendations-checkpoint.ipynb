{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67b87e4d",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\" width=100>\n",
    "</div>\n",
    "\n",
    "# Project 2: Ames Housing Data and Kaggle Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f71c321",
   "metadata": {},
   "source": [
    "## Background\n",
    "The Ames Housing Dataset is an exceptionally detailed and robust dataset with over 70 columns of different features relating to houses.  \n",
    "We are presented with this dataset to predict the prices of the houses in Ames, Iowa.  \n",
    "The data is taken  from: https://www.kaggle.com/c/dsi-us-11-project-2-regression-challenge/data\n",
    "\n",
    "## Problem Statement\n",
    "As a consultant to the house-owner in the city of Ames of Iowa, I am presented with the challenge of finding the features that will affect the sale price of the house. In doing so, I will then be able to give recommendations to the house-owner in order to increase the value of the house."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdca8ad",
   "metadata": {},
   "source": [
    "## Progress thus far\n",
    "In Part 1, we have cleaned the provided datasets and selected the following features out of the original 80 features that will be used for our modelling process.\n",
    "\n",
    "|Feature|Description|\n",
    "|:--:|:----------:|\n",
    "|**id**|  |\n",
    "|**saleprice**| The Id of the property |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4163d82c",
   "metadata": {},
   "source": [
    "## Part 2: Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bfa57c",
   "metadata": {},
   "source": [
    "### 1. Importing the libraries (All libraries used will be added here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdd9a755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bdd8a8",
   "metadata": {},
   "source": [
    "### 2. Importing the training dataset and the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9023671",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean = pd.read_csv('../datasets/train_clean.csv')\n",
    "\n",
    "df_test_clean = pd.read_csv('../datasets/test_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea9313d",
   "metadata": {},
   "source": [
    "### 3. Train/Test Split\n",
    "As we are unable to confirm the results of our modelling if we are to immediately predict on the test dataset since the `SalePrice` for the test dataset is not provided, if we are to evaluate our models, we will have to split up the training dataset into train data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78718685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the features for the modelling\n",
    "features = [feat for feat in df_train_clean.columns if feat != 'saleprice' and feat != 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70550202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2051, 25)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2051,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(878, 25)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating the X and y variables from the training dataset\n",
    "X = df_train_clean[features]\n",
    "y = df_train_clean['saleprice']\n",
    "\n",
    "# Creating the X variable from the test dataset [Using X_kaggle here to differ from the X_test later]\n",
    "X_kaggle = df_test_clean[features]\n",
    "\n",
    "# Displaying the shapes of the X and y variables\n",
    "display(X.shape)\n",
    "display(y.shape)\n",
    "display(X_kaggle.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e66b6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635317d7",
   "metadata": {},
   "source": [
    "### 4. Baseline Model\n",
    "For the Baseline Model for the prediction of the `SalePrice`, we will be using the mean value of `SalePrice` from the train data above as the predictions for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac9e2fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181061.9934980494"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The mean value of SalePrice\n",
    "np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2b1d4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79526.85223710592"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE for the train data\n",
    "y_pred_base = np.ones_like(y_train) * np.mean(y_train)\n",
    "np.sqrt(mean_squared_error(y_train, y_pred_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aae39c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78375.26238032707"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE for the test data\n",
    "y_pred_base = np.ones_like(y_test) * np.mean(y_train)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d05996",
   "metadata": {},
   "source": [
    "For the Baseline Model, the RMSE for the train set and the test set are 79526.8522 and 78375.2624 respectively. Considering the RMSE for the sample provided by Kaggle is at 83945.31, this is somewhat expected for the Baseline Model.\n",
    "\n",
    "From here on, we just have to improve on this score by modelling the data on the appriopriate models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f9dfe4",
   "metadata": {},
   "source": [
    "### 5. Model Fitting and Evaluation\n",
    "At this point in time, we will be fitting the given data to a multi-variable linear regression model. As we have checked the linear relationships in Part 1, we will not be doing these here again. \n",
    "\n",
    "Also, to evaluate the models, we will be looking at the three metrics: _Root Mean Squared Error (RMSE), Mean Absolute Error (MAE) and Coefficient of Determination, $R^2$_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1e7c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for metrics (Since we will be using this often)\n",
    "def model_metrics(model, X_mod, y_mod):\n",
    "    # Predicting the y values based on the given X_mod\n",
    "    y_mod_pred = model.predict(X_mod)       \n",
    "    \n",
    "    # Printing the metrics data\n",
    "    print(f'RMSE: {round(np.sqrt(mean_squared_error(y_mod, y_mod_pred)), 4)}')\n",
    "    print(f'MAE: {round(mean_absolute_error(y_mod, y_mod_pred), 4)}')\n",
    "    print(f'R2: {round(r2_score(y_mod, y_mod_pred), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6141baab",
   "metadata": {},
   "source": [
    "### 5.1 Scaling of data\n",
    "As our later models using Ridge and Lasso would require us to scale our data prior to modelling, we will be scaling the features in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e0325e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns that need to be scaled, taken from Part 1, dummy columns do not need to be scaled\n",
    "scale_cols = ['lot_area',\n",
    "              'overall_qual', \n",
    "              'year_built', \n",
    "              'exter_qual', \n",
    "              'bsmt_qual', \n",
    "              'bsmt_exposure', \n",
    "              'total_bsmt_sf', \n",
    "              'heating_qc', \n",
    "              'gr_liv_area', \n",
    "              'full_bath', \n",
    "              'kitchen_qual', \n",
    "              'totrms_abvgrd', \n",
    "              'fireplaces', \n",
    "              'garage_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2bd848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the scaled dataframes in order to avoid the transformation of the original dataframes\n",
    "Z_train = X_train.copy()\n",
    "Z_test = X_test.copy()\n",
    "Z_kaggle = X_kaggle.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f12391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the StandardScaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "Z_train[scale_cols] = ss.fit_transform(Z_train[scale_cols])\n",
    "\n",
    "#Transform the testing data and the kaggle test dataset\n",
    "Z_test[scale_cols] = ss.transform(Z_test[scale_cols])\n",
    "Z_kaggle[scale_cols] = ss.transform(Z_kaggle[scale_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423e7932",
   "metadata": {},
   "source": [
    "### 5.2 Linear Regression\n",
    "Our first model to start off will be the Ordinary Least Squares Linear Regression or OLS. \n",
    "\n",
    "Since we have both the scaled and the unscaled data to model from, we will be using both here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc344589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Unscaled data\n",
    "# Initializing and fitting the model \n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7823a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 30832.4528\n",
      "MAE: 19940.5007\n",
      "R2: 0.8497\n"
     ]
    }
   ],
   "source": [
    "# Metrics for Linear Regression with Unscaled data for the training data\n",
    "model_metrics(lr, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "457a72c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 26923.1815\n",
      "MAE: 19641.124\n",
      "R2: 0.8819\n"
     ]
    }
   ],
   "source": [
    "# Metrics for Linear Regression with Unscaled data for the test data\n",
    "model_metrics(lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fe90206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8325085355893315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cross validation score for Linear Regression with Unscaled data\n",
    "display(cross_val_score(lr, X_train, y_train, cv=10).mean())\n",
    "# display(cross_val_score(lr, X_train, y_train, scoring='neg_mean_squared_error', cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "234554bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.24765778e+00,  1.10308594e+04,  1.32165341e+02,  1.08464410e+04,\n",
       "        5.26016505e+03,  6.46223403e+03, -2.94178731e+00,  3.47357664e+03,\n",
       "        5.23488580e+01, -1.46166120e+03,  9.81290396e+03,  6.71414136e+02,\n",
       "        8.65868952e+03,  2.70092921e+01,  6.02151979e+04,  4.44652129e+04,\n",
       "        3.79653563e+04,  8.28727051e+03,  2.74152354e+03,  1.84104942e+03,\n",
       "       -6.13998667e+02,  1.18962525e+04, -4.21136040e+03,  6.03822142e+03,\n",
       "       -4.44055455e+01])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coefficients of Linear Regression with Unscaled data\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6956c6",
   "metadata": {},
   "source": [
    "The R2 scores for both the training and test data are 0.8497 and 0.8819, which is good since we are looking at how well the model is performing. However the cross validation score of 0.8325 differs quite a bit from the R2 score, so the model does not work so well on unseen data. \n",
    "\n",
    "The RMSE for the train and test data are at 30832.4528 and 26923.1815 respectively, which is an improvement from the baseline scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69b9c6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Scaled data\n",
    "# Initializing and fitting the model \n",
    "lr_ss = LinearRegression()\n",
    "lr_ss.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "592f05d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 30832.4528\n",
      "MAE: 19940.5007\n",
      "R2: 0.8497\n"
     ]
    }
   ],
   "source": [
    "# Metrics for Linear Regression with Scaled data for the training data\n",
    "model_metrics(lr_ss, Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1dc89e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 26923.1815\n",
      "MAE: 19641.124\n",
      "R2: 0.8819\n"
     ]
    }
   ],
   "source": [
    "# Metrics for Linear Regression with Scaled data for the test data\n",
    "model_metrics(lr_ss, Z_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58dc1165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8325085355893307"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation score for Linear Regression with Scaled data\n",
    "cross_val_score(lr_ss, Z_train, y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f1f974e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.11316263e+03,  1.57524810e+04,  3.98663953e+03,  6.32788041e+03,\n",
       "        4.70107621e+03,  6.90360309e+03, -1.33918917e+03,  3.38460825e+03,\n",
       "        2.59577443e+04, -8.08431568e+02,  6.54494878e+03,  1.04884543e+03,\n",
       "        5.51075653e+03,  5.89329917e+03,  6.02151979e+04,  4.44652129e+04,\n",
       "        3.79653563e+04,  8.28727051e+03,  2.74152354e+03,  1.84104942e+03,\n",
       "       -6.13998667e+02,  1.18962525e+04, -4.21136040e+03,  6.03822142e+03,\n",
       "       -4.44055455e+01])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coefficients of Linear Regression with Scaled data\n",
    "lr_ss.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8ab83e",
   "metadata": {},
   "source": [
    "We have the exact same scores for both unscaled and scaled data. This should not be a surprise since scaling only standardizes the X values and does not affect the modelling in any way. The only difference is the coefficients of the model due to the scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4474ba",
   "metadata": {},
   "source": [
    "### 5.3 Ridge Regression\n",
    "The next step is regularization. First off, we will start with Ridge Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c6a7a9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([1.00000000e+00, 1.12332403e+00, 1.26185688e+00, 1.41747416e+00,\n",
       "       1.59228279e+00, 1.78864953e+00, 2.00923300e+00, 2.25701972e+00,\n",
       "       2.53536449e+00, 2.84803587e+00, 3.19926714e+00, 3.59381366e+00,\n",
       "       4.03701726e+00, 4.53487851e+00, 5.09413801e+00, 5.72236766e+00,\n",
       "       6.42807312e+00, 7.22080902e+00, 8.11130831e+00, 9.11162756e+00,\n",
       "       1.02353102e+01, 1.14975700e+0...\n",
       "       6.89261210e+03, 7.74263683e+03, 8.69749003e+03, 9.77009957e+03,\n",
       "       1.09749877e+04, 1.23284674e+04, 1.38488637e+04, 1.55567614e+04,\n",
       "       1.74752840e+04, 1.96304065e+04, 2.20513074e+04, 2.47707636e+04,\n",
       "       2.78255940e+04, 3.12571585e+04, 3.51119173e+04, 3.94420606e+04,\n",
       "       4.43062146e+04, 4.97702356e+04, 5.59081018e+04, 6.28029144e+04,\n",
       "       7.05480231e+04, 7.92482898e+04, 8.90215085e+04, 1.00000000e+05]),\n",
       "        cv=10, scoring='r2')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing and fitting the model \n",
    "r_alphas = np.logspace(0,5,100)\n",
    "ridge_cv = RidgeCV(alphas=r_alphas, scoring='r2', cv=10)\n",
    "ridge_cv.fit(Z_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cad59341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8480358684358014"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimal value of alpha \n",
    "ridge_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "758fbee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=2.8480358684358014)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate and fitting Ridge with the optimal value of alpha\n",
    "ridge = Ridge(alpha=ridge_cv.alpha_)\n",
    "ridge.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7a975ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 30850.6322\n",
      "MAE: 19923.4464\n",
      "R2: 0.8495\n"
     ]
    }
   ],
   "source": [
    "# Metrics for Ridge for the training data\n",
    "model_metrics(ridge, Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9d8f5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 26738.2836\n",
      "MAE: 19623.7797\n",
      "R2: 0.8836\n"
     ]
    }
   ],
   "source": [
    "# Metrics for Ridge for the test data\n",
    "model_metrics(ridge, Z_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d7ada1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8327419700176986"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation score for Linear Regression with Scaled data\n",
    "cross_val_score(ridge, Z_train, y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edf12fc",
   "metadata": {},
   "source": [
    "### 5.4 Lasso Regression\n",
    "After Ridge Regression, we will try Lasso Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4945b799",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(cv=10, n_alphas=500)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing and fitting the model \n",
    "lasso_cv = LassoCV(n_alphas=500, cv=10)\n",
    "lasso_cv.fit(Z_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee226e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122.99946170715148"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimal value of alpha \n",
    "lasso_cv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70f4dc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=122.99946170715148)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate and fitting Lasso with the optimal value of alpha\n",
    "lasso = Lasso(alpha=lasso_cv.alpha_)\n",
    "lasso.fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d32cf45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 30890.0557\n",
      "MAE: 19841.8641\n",
      "R2: 0.8491\n"
     ]
    }
   ],
   "source": [
    "# Metrics for Ridge for the training data\n",
    "model_metrics(lasso, Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8657da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 26590.7275\n",
      "MAE: 19485.1481\n",
      "R2: 0.8848\n"
     ]
    }
   ],
   "source": [
    "# Metrics for Ridge for the test data\n",
    "model_metrics(lasso, Z_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f86251e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8333717846630158"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation score for Linear Regression with Scaled data\n",
    "cross_val_score(lasso, Z_train, y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9bb947",
   "metadata": {},
   "source": [
    "### 6 Final Model\n",
    "`To be Added`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
